{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T09:23:31.397656Z",
     "start_time": "2021-04-13T09:23:31.387727Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f2c17f1277da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model.Model import Seq2Seq\n",
    "from model.Encoder import Encoder\n",
    "from model.Decoder import Decoder\n",
    "from utilities.inference import translate_sentence_with_guidance, postprocessing, get_all_table_columns\n",
    "from utilities.build_vocab import build_vocab\n",
    "from utilities.vis_rendering import VisRendering\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from vega import VegaLite\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T09:13:16.777575Z",
     "start_time": "2021-04-13T09:13:16.654148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: conda\r\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            tok_types = batch.tok_types\n",
    "\n",
    "            output, _ = model(src, trg[:, :-1], tok_types, SRC)\n",
    "\n",
    "            # output = [batch size, trg len - 1, output dim]\n",
    "            # trg = [batch size, trg len]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            # output = [batch size * trg len - 1, output dim]\n",
    "            # trg = [batch size * trg len - 1]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(\"------------------------------\\n| Build vocab start ... | \\n------------------------------\")\n",
    "SRC, TRG, TOK_TYPES, BATCH_SIZE, train_iterator, valid_iterator, test_iterator, my_max_length = build_vocab(\n",
    "    path_to_training_data='./dataset/dataset_final/',\n",
    "    path_to_db_info='./dataset/database_information.csv'\n",
    ")\n",
    "print(\"------------------------------\\n| Build vocab end ... | \\n------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256  # it equals to embedding dimension # 原来256，可以改成standard的512试一试\n",
    "ENC_LAYERS = 3  # 3--> 6\n",
    "DEC_LAYERS = 3  # 3-->6\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM,\n",
    "              HID_DIM,\n",
    "              ENC_LAYERS,\n",
    "              ENC_HEADS,\n",
    "              ENC_PF_DIM,\n",
    "              ENC_DROPOUT,\n",
    "              device,\n",
    "              TOK_TYPES,\n",
    "              my_max_length\n",
    "              )\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM,\n",
    "              HID_DIM,\n",
    "              DEC_LAYERS,\n",
    "              DEC_HEADS,\n",
    "              DEC_PF_DIM,\n",
    "              DEC_DROPOUT,\n",
    "              device,\n",
    "              my_max_length\n",
    "              )\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)  # define the Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./save_models/model_best.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tables_columns = get_all_table_columns('./dataset/db_tables_columns.json')\n",
    "\n",
    "test_df = pd.read_csv('./dataset/dataset_final/test.csv')\n",
    "\n",
    "# shuffle your dataframe in-place and reset the index\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "nl_acc = []\n",
    "nl_chart_acc = []\n",
    "\n",
    "test_result = []  # tvBench_id, chart_type, hardness, ifChartTemplate, ifRight=1\n",
    "\n",
    "only_nl_cnt = 0\n",
    "only_nl_match = 0\n",
    "\n",
    "nl_template_cnt = 0\n",
    "nl_template_match = 0\n",
    "i = 0\n",
    "\n",
    "create_vis = VisRendering()\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    gold_query = row['labels'].lower()\n",
    "\n",
    "    src = row['source'].lower()\n",
    "    i += 1\n",
    "\n",
    "    tok_types = row['token_types']\n",
    "\n",
    "    translation, attention, enc_attention = translate_sentence_with_guidance(\n",
    "        row['db_id'], gold_query.split(' ')[gold_query.split(' ').index('from') + 1],\n",
    "        src, SRC, TRG, TOK_TYPES, tok_types, SRC, model, db_tables_columns, device, my_max_length\n",
    "    )\n",
    "\n",
    "    pred_query = ' '.join(translation).replace(' <eos>', '').lower()\n",
    "    old_pred_query = pred_query\n",
    "\n",
    "    if '[c]' not in src:\n",
    "        # with template\n",
    "        pred_query = postprocessing(gold_query, pred_query, True, src)\n",
    "\n",
    "        nl_template_cnt += 1\n",
    "\n",
    "        if ' '.join(gold_query.replace('\"', \"'\").split()) == ' '.join(pred_query.replace('\"', \"'\").split()):\n",
    "            print(' '.join(pred_query.replace('\"', \"'\").split()))\n",
    "            vis_query = create_vis.parse_output_query(\n",
    "                ' '.join(pred_query.replace('\"', \"'\").split())\n",
    "            )\n",
    "\n",
    "            data4vis = create_vis.query_sqlite3(\n",
    "                '../SEQ2VIS+BERT/Transformer-BERT/Code/dataset/spider/database/',\n",
    "                row['db_id'],\n",
    "                vis_query['data_part']['sql_part']\n",
    "            )\n",
    "\n",
    "            create_vis.render_vis(data4vis, vis_query)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if '[c]' in src:\n",
    "        # without template\n",
    "        pred_query = postprocessing(gold_query, pred_query, False, src)\n",
    "\n",
    "        only_nl_cnt += 1\n",
    "        if ' '.join(gold_query.replace('\"', \"'\").split()) == ' '.join(pred_query.replace('\"', \"'\").split()):\n",
    "            print(' '.join(pred_query.replace('\"', \"'\").split()))\n",
    "            vis_query = create_vis.parse_output_query(\n",
    "                ' '.join(pred_query.replace('\"', \"'\").split())\n",
    "            )\n",
    "\n",
    "            data4vis = create_vis.query_sqlite3(\n",
    "                '../SEQ2VIS+BERT/Transformer-BERT/Code/dataset/spider/database/',\n",
    "                row['db_id'],\n",
    "                vis_query['data_part']['sql_part']\n",
    "            )\n",
    "\n",
    "            create_vis.render_vis(data4vis, vis_query)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if index > 20:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
